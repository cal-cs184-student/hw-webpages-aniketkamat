<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Aniket Kamat</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-aniketkamat/hw1/">https://cal-cs184-student.github.io/hw-webpages-aniketkamat/hw1/</a>
		
		<br>

		Link to GitHub repository:<a href="https://github.com/cal-cs184-student/hw1-rasterizer-teama">https://github.com/cal-cs184-student/hw1-rasterizer-teama/sp25</a>
			
		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this assignment, I implemented a rasterizer that can help display SVG files. It uses tools like antialiasing and pixel/level sampling to make the 2D image on the computer screen look more realistic and appear to have gradient/texture features. It helped me learn how to use simpler techniques such as triangle rendering and matrix multiplication to solve complex display problems.
		One interesting thing I learned was that the supersampling method is unexpectedly good for how simple it is to implement compared to many other methods. When I was doing the extra credit for Task 2, I experimented with a few different filtering techniques and saw that most others either produced worse artifacts or more uneven coloring.
			
		<h2>Task 1: Drawing Single-Color Triangles</h2>
		There are two main mathematical ideas behind displaying a triangle. The first is that a line with endpoints (X_i, Y_i) and (X_(i+1), Y_(i+1)) is uniquely defined by the zeros of its function:  <li>\[-(x - X_i)(Y_{i+1} - Y_i) + (y - Y_i)(X_{i+1} - X_i)\]</li> and that this same function can split the plane into two parts (half-planes), where one contains the (x,y) points where this function is greater than 0 and one half-plane for when this function is less than 0. 
		The second idea is that since a triangle is defined by three sides (lines), we can define the inside of the triangle as the area where three of the half-planes from the three lines overlap. To check if a point is 'in' a triangle, we can check if it is in each half-plane. So, we can iterate over all potential points that are in the triangle and check each of them, filling in the corresponding pixel if they are. 
		The algorithm is to use the minimum and maximum values of the given vertex coordinates (min X, min Y, max X, max Y) to define a box and scan over all points in this box. For each pixel, we compute the equation above for each possible pair of given vertices (defining the center coordinates of the pixel as (x,y), one vertex as (X_i, Y_i) and the other vertex as (X_i+1, Y_i+1)). Since the given ordering of the vertices may be clockwise or counterclockwise, we test that the line equations are either all >= 0 or all <= 0 to account for orientation.
		My final algorithm is simple bounding box triangle rasterization with further optimizations described below, so it is not worse than simple bounding box triangle rasterization. 
		<br>
		<b>Extra Credit</b>
			
		<table>
		  <thead>
		    <tr>
		      <th>Improvements</th>
		      <th>Approximate Average Triangle Generation Time (ms)</th>
		    </tr>
		  </thead>
		  <tbody>
		    <tr>
		      <td>Basic</td>
		      <td>5.40e-03</td>
		    </tr>
		    <tr>
		      <td>Combining Loops and Limiting Lookups</td>
		      <td>3.71e-03</td>
			</tr>
		    <tr>
		      <td>Implementing Parallelism</td>
		      <td>2.37e-03</td>
		    </tr>
		  </tbody>
			
		</table>
		<br>
		The clock times measured with  <code>clock()</code>  had high variance, so the values were averaged over 3 sets of ~10,000 triangles (by running test3 a few times). The optimizations involved implementing parallelism with OpenMP, limiting memory lookups by computing the line equation only once, and looping over the points only once for both orientations. Interestingly, while implementing parallelism with  <code>#pragma omp parallel for</code>  reduced the run time, collapsing the loops with <code>#pragma omp parallel for collapse(2)</code> performed worse than even the purely serial version.
		<figure>
		<img src="test4.png" alt="Test 4" style="width:50%"/>
		<figcaption>Single-Color Triangle Rasterization</figcaption>
		</figure>
		The 'strict' nature of the identity function (because the center of a point is either in or out) can lead to some unusual behavior in edge cases as seen in the pixel inspector above. The red triangle is very thin, so there are some errors (noncontinuity) in displaying it as the centers of the pixels in between the two red areas technically do not fall inside the triangle. 	
		<h2>Task 2: Antialiasing by Supersampling</h2>
		To implement supersampling, I started with the same algorithm I had used in Task 1 to iterate over the bounding box of the triangle. However, instead of just checking the center of each pixel, I now added two for loops to iterate over a sample rate number of points in each pixel. This was done by checking sqrt(sample rate) x coordinates and sqrt(sample rate) y coordinates for each pixel and keeping track of how many (x,y) pairs were in the triangle for each pixel. The proportion of pairs that were in the triangle for each pixel determined the color of the pixel (more subsamples in the triangle meant that the pixel color would be closer to the given triangle color).
		It is useful since it often helps reduce aliasing/jaggies and produces a smoother image. The biggest modification I made to the pipeline was changing when the pixel itself was colored. In the first task, the pixels were filled right after the centers were checked with <code> fill_pixel(x, y, color) </code>. For supersampling, we instead relied on  <code> resolve_to_framebuffer() </code> by storing the number of subsamples that passed the test for each pixel in an array, computing the proportion of the points in the pixel that were in the triangle, determining the 'level' of color that proportion would correspond to, and then actually filling it. 
		As seen in the three images below, this helped antialias the triangles by allowing for pixels with centers 'near' a triangle's edges to still be colored. When supersampling was not being used (rate of 1), there is a gap between parts of the triangle on the left. As the rate increases to 4 and 16 (two triangles on the right), the triangle looks smoother since the pixels with centers not in the triangle but that are partially in it are given lighter shades, creating a more natural, connected look. 
		<table>
		  <tr>
		    <td><figure><img src="rateof1.png" width="360" height="270" alt="Rate of 1"><figcaption>Supersampled with Rate of 1</figcaption></figure></td>
		    <td><figure><img src="rateof4.png" width="360" height="270" alt="Rate of 4"><figcaption>Supersampled with Rate of 4</figcaption></figure></td>
		    <td><figure><img src="rateof16.png" width="360" height="270" alt="Rate of 16"><figcaption>Supersampled with Rate of 16</figcaption></figure></td>
		  </tr>
		</table>
		These results are observed since a few of the pixels near the area the pixel inspector is on are partially in the triangle, but their centers are not. With a rate of 1, these pixels are not colored, resulting in the 'broken' look on the left. The higher rate allows for the program to get a better idea of how much of the pixel is in the triangle and give it a lighter shade, creating the smoother, connected look in the images in the middle and on the right.
		<b>Extra Credit</b>
		I implemented an alternative antialiasing method by developing a system for weighing the samples within each pixel. The idea behind it is that a sample closer to the center of the pixel should be weighed more than at the very edge of the pixel. To implement this, I wrote a helper function that constructs a normalized, pyramid-shaped weighted matrix given the sample rate and modified <code> resolve_to_framebuffer() </code> to weigh each sample when summing them up and not normalize after. The table below shows the results. The most prominent difference is between the two 'Rate of 16' images where (in the image below) the pixels largely in between the edges of the triangle are more red while the ones mostly on the side are less prominent.
		<table>
		  <tr>
		    <td><figure><img src="ec1part2.png" width="360" height="270" alt="Rate of 1"><figcaption>Supersampled with Rate of 1</figcaption></figure></td>
		    <td><figure><img src="ec2part2.png" width="360" height="270" alt="Rate of 4"><figcaption>Supersampled with Rate of 4</figcaption></figure></td>
		    <td><figure><img src="ec3part2.png" width="360" height="270" alt="Rate of 16"><figcaption>Supersampled with Rate of 16</figcaption></figure></td>
		  </tr>
		</table>
		<h2>Task 3: Transforms</h2>
		In this task, I implemented transforms by defining the 3x3 matrices associated with translating, rotating, and scaling. Cubeman is shown below performing a jumping jack with its arms and legs rotated. The process of performing a jumping jack has brought immeasurable joy to cubeman's life, resulting in its inner limbs and face turning different colors.
		<figure>
		<img src="my_robot.png" alt="My Robot" style="width:50%"/>
		<figcaption>Multi-Colored Cubeman Performing a Jumping Jack</figcaption>
		</figure>
		<h2>Task 4: Barycentric coordinates</h2>
		Barycentric coordinates are an alternative method of evaluating points within a triangle. They give each point a weight that represents how much a certain vertex 'contributes' to a point. For a concrete example, consider the image of the multi-colored triangle on the left below. Place your cursor on the red vertex at the bottom and bring it roughly 80% of the way towards the top side of the triangle. 
		From here, first imagine one line connecting your cursor to the blue vertex on the right and a second line connecting your cursor to the green vertex on the left. These two lines as well as the line between the green and blue vertex define a third triangle entirely contained within the multi-colored one. 
		Repeating this process for the other two sets of vertices as well (blue/red and green/red) gives three total triangles that are entirely contained with the larger one and with areas that sum to the area of the larger one. The Barycentric Corrdinate system uses the area of these triangles to assign weights to the vertex not used in the calculation. In the case of the first triangle (calculated with the blue and green vertices), that would mean that the larger the area is, the more weight assigned to the red vertex.
		Now move your cursor halfway towards the red and imagine the same two lines to the blue/green vertex as above. You can see that the area of the triangle has increased as the point got closer to the red vertex which suggests that more of the red 'contributed' to this point. Barycentric coordinates use this ratio of areas as the weights, which can then be used to perform 3 edge tests (check if all non-negative or non-positive) and to construct the color by weighing each vertex by the corresponding ratio. 
		If you take your cursor back to 80% of the way to the top, you can see the colors of the pixels in the area on the pixel inspector. The points are fairly far away from the red vertex so they are mostly green and blue, and you can see that the points on the left have more green since the Barycentric coordinate process weighed the green vertex more.
		<table>
		  <tr>
		    <td><figure><img src="teachwith.png" width="600" height="450" alt="Teach With"><figcaption>Multi-colored Triangle</figcaption></figure></td>
		    <td><figure><img src="test7.png" width="600" height="450" alt="Test 7"><figcaption>Color Wheel</figcaption></figure></td>
		  </tr>
		</table>
		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		Pixel sampling is a tool for creating a texture effect by choosing colors for the pixels in a rasterized triangle from a texture image. Texture mapping aims to use a 2D texture (image) and place (map) it onto a 3D object to create a more detailed and realistic model. In this case, I implemented this by assigning a 2D coordinate (u,v) to each pointt in the texture image. I computed the Barycentric coordinates for each point in the triangle I was attempting to rasterize and with those weights (say a0,b0,c0), computed the (u,v) coordinates using the given (u,v) coordinates for each vertex.
		For a given vertex (called a), I was given the (x_a,y_b) coordinates as well as the corresponding (u_a,v_a) coordinates on the texture, so now that I had the corresponding weight a_0 from the Barycentric process, I computed the (u_p,v_p) coordinates for a point p in the triangle using the following equation (where b, c represent the other two vertices):
		<li>\[(u_p, v_p) = a_0*(u_a, v_a) + b_0*(u_b, v_b) + c_0*(u_c, v_c) \]</li>
		I scaled this up to the texture size and then sampled from that point on the texture to figure out the color for that point. There were two main methods of sampling. The nearest method simply took the color from the nearest texel on the texture while the bilinear method took the average of the four nearest texels (defined as the texels exactly one unit away on either the u or v axis). In general, the nearest method produces sharper images while the bilinear method produces smoother images. The difference is large when looking closely at an image as the nearest method will look blockier while the bilinear method will show a clearer transition between texels. This is especially visible in high frequency images as the bilinear method may produce more blurs and less jaggies compared to the nearest method.
		<table>
		  <tr>
		    <td><figure><img src="5fixed1.png" width="300" height="225" alt="Nearest Sampling at 1 Sample Per Pixel"><figcaption>Nearest Sampling at 1 Sample Per Pixel</figcaption></figure></td>
		    <td><figure><img src="5fixed3.png" width="300" height="225" alt="Bilinear Sampling at 1 Sample Per Pixel"><figcaption>Bilinear Sampling at 1 Sample Per Pixel</figcaption></figure></td>
		    <td><figure><img src="5fixed2.png" width="300" height="225" alt="Nearest Sampling at 16 Samples Per Pixel"><figcaption>Nearest Sampling at 16 Samples Per Pixel</figcaption></figure></td>
			<td><figure><img src="5fixed4.png" width="300" height="225" alt="Bilinear Sampling at 16 Samples Per Pixel"><figcaption>Bilinear Sampling at 16 Samples Per Pixel</figcaption></figure></td>
		  </tr>
		</table>
		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		Level sampling is a tool for creating a texture effect by deciding the level of resolution of the texture map from which to sample from. In task 5, we always sampled from the original texture, but sampling from different levels (such as half or quarter or eight resolution which are levels in a 'mipmap' pyramid) can reduce aliasing by acting as a prefiltering method.
		I implemented this by using the same Barycentric interpolation process as Task 5, but I now try to figure out how 'fast' the texels change in that part of the image by estimating the change in (u,v) for a nearby point and adjusting for the size of the texture. I take the max of the two 'texels per pixel' rates and choose the level from the pyramid (ie. mipmap level) by taking the log of that value.
		When the chosen level sampling method is L_ZERO, I sample from the 0th level (top of the pyramid/full resolution image as in Task 5). When it is L_NEAREST, I round to the nearest mipmap level and use that for the sampling function. When it is L_LINEAR, I compute the mipmaps for the number below and above the value and use a weighted sum to compute an interpolated value to use. 
		Pixel sampling is the fastest (with nearest faster than bilinear) and has low memory usage as only the original texture needs to be saved. Level sampling is slightly slower since derivatives need to be approximated and (in the case of L_LINEAR) multiple mipmaps need to be computed/interpolated, and uses slightly more memory for the mipmap pyramid. The number of samples per pixel is the slowest as increasing the sample rate increases the number of computations by about the same (eg. 16x sample rate requires testing 16x as many points) and requires more memory for the sample buffer (to store the results of the added computations/identity functions).
		Pixel sampling helps with antialiasing when looking at the image closely and can produce blockier/smoother effects (with nearest/linear) if desired. However, level sampling is better for antialiasing when it comes to 'far away effects' as it can reduce moire. Increasing the samples per pixel has the most antialiasing power as it can produce a smoother image and help reduce moire.  
		<table>
		  <tr>
		    <td><figure><img src="6fixed1.png" width="300" height="225" alt="L_ZERO and P_NEAREST"><figcaption>L_ZERO and P_NEAREST</figcaption></figure></td>
		    <td><figure><img src="6fixed2.png" width="300" height="225" alt="L_ZERO and P_LINEAR"><figcaption>L_ZERO and P_LINEAR</figcaption></figure></td>
		    <td><figure><img src="6fixed3.png" width="300" height="225" alt="L_NEAREST and P_NEAREST"><figcaption>L_NEAREST and P_NEAREST</figcaption></figure></td>
			<td><figure><img src="6fixed4.png" width="300" height="225" alt="L_NEAREST and P_LINEAR"><figcaption>L_NEAREST and P_LINEAR</figcaption></figure></td>
		  </tr>
		</table>
		</div>
	</body>
</html>
